{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Song Lyric Generation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOUuWDco6bbZInVglGcuudQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sproboticworks/ml-course/blob/master/NLP%20Song%20Lyric%20Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZBzjOrhvJPo",
        "colab_type": "text"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibbqXFpLvCdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1KY4GQBuN3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/sproboticworks/master/assets/datasets/irish-lyrics-eof.txt \\\n",
        "    -O /tmp/irish-lyrics-eof.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD7xUHw8vMvT",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-hsFCjAvTQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "data = open('/tmp/irish-lyrics-eof.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print('Total Words: {}'.format(total_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpH9dNcmvXRW",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZayyDMJFvZUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequences = []\n",
        "for index, line in enumerate(corpus):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "    if index == 0:\n",
        "        print(\"'\"+line+\"' => {}\".format(token_list))\n",
        "        print(\"Input Sequences :\")\n",
        "        print('\\n'.join(map(str, input_sequences)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzU4pSJP4W4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "first_line_len = len(corpus[0].split()) \n",
        "print(\"Padded Input Sequences for the first line :\")\n",
        "print(input_sequences[:first_line_len-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcC-yHOs4Yx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs = input_sequences[:,:-1]\n",
        "labels = input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-2SO23hv9g4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Consider first sentence\n",
        "print(\"Sentence : {}\".format(corpus[0]))\n",
        "print(\"Tokens : {}\".format(input_sequences[first_line_len-2]))\n",
        "print(\"X : {}\".format(xs[first_line_len-2]))\n",
        "print(\"Label : {}\".format(labels[first_line_len-2]))\n",
        "print(\"Y : {}\".format(ys[first_line_len-2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf332STewG8s",
        "colab_type": "text"
      },
      "source": [
        "#Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6zioxu1wIY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 100\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(total_words, embedding_dim, input_length=max_sequence_len-1),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)),\n",
        "    tf.keras.layers.Dense(total_words, activation='softmax')                            \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLA0enWGwock",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.01), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjNT2-3two8f",
        "colab_type": "text"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlLfTvISwrlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(xs, ys, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6AD8p2wwuMT",
        "colab_type": "text"
      },
      "source": [
        "# Visualize Training Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF1LbAz5wwEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAkGjD6jwx1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDdWSAHdw0DE",
        "colab_type": "text"
      },
      "source": [
        "#Generate Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRgFlKHUw2L8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text = \"With great power comes great responsibility\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted_labels = model.predict(token_list, verbose=0)\n",
        "\tpredicted_index = np.argmax(predicted_labels, axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted_index:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}